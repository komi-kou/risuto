#!/usr/bin/env python3
"""
å…¨ã‚«ãƒ†ã‚´ãƒªï¼ˆåœ°åŸŸãƒ»ä¾¡æ ¼ãƒ»ç‰¹å¾´ãƒ»æ¥­ç¨®ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ã—ã¦æœ€çµ‚CSVä½œæˆ
"""
import json
import csv
from datetime import datetime
from collections import defaultdict

def merge_all_categories():
    """å…¨ã‚«ãƒ†ã‚´ãƒªã‚’ãƒãƒ¼ã‚¸"""
    
    print("="*80)
    print("å…¨ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸")
    print(f"å‡¦ç†é–‹å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    all_data = []
    
    # 1. åœ°åŸŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print("\n1. åœ°åŸŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    try:
        with open('area_all_data_20250812_154808.json', 'r', encoding='utf-8') as f:
            area_data = json.load(f)
            all_data.extend(area_data)
            print(f"   âœ… {len(area_data):,}ä»¶")
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 2. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print("\n2. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    try:
        with open('price_complete_20250812_192022.json', 'r', encoding='utf-8') as f:
            price_data = json.load(f)
            all_data.extend(price_data)
            print(f"   âœ… {len(price_data):,}ä»¶")
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print("\n3. ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    try:
        with open('feature_all_data_20250812_114221.json', 'r', encoding='utf-8') as f:
            feature_data = json.load(f)
            all_data.extend(feature_data)
            print(f"   âœ… {len(feature_data):,}ä»¶")
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print("\n4. æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    try:
        with open('industry_all_complete_20250813_233813.json', 'r', encoding='utf-8') as f:
            industry_data = json.load(f)
            all_data.extend(industry_data)
            print(f"   âœ… {len(industry_data):,}ä»¶")
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_data):,}ä»¶")
    
    # ã‚«ãƒ†ã‚´ãƒªã‚°ãƒ«ãƒ¼ãƒ—åˆ¥é›†è¨ˆ
    category_counts = defaultdict(int)
    for record in all_data:
        group = record.get('category_group', 'unknown')
        category_counts[group] += 1
    
    print("\nã‚«ãƒ†ã‚´ãƒªã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:")
    for group, count in sorted(category_counts.items()):
        print(f"  {group}: {count:,}ä»¶")
    
    # ä¼æ¥­ã”ã¨ã«ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’é›†ç´„
    companies = defaultdict(lambda: {
        'company_name': '',
        'official_site_url': '',
        'yuryoweb_url': '',
        'addresses': set(),
        'area_categories': set(),
        'price_categories': set(),
        'feature_categories': set(),
        'industry_categories': set()
    })
    
    for record in all_data:
        url = record.get('official_site_url', '').strip()
        if not url:
            continue
        
        company = companies[url]
        company['company_name'] = record.get('company_name', '')
        company['official_site_url'] = url
        company['yuryoweb_url'] = record.get('yuryoweb_url', '')
        
        address = record.get('address', '').strip()
        if address:
            company['addresses'].add(address)
        
        category_group = record.get('category_group', '')
        category_name = record.get('category_name', '')
        
        if category_group == 'area':
            company['area_categories'].add(category_name)
        elif category_group == 'price':
            company['price_categories'].add(category_name)
        elif category_group == 'feature':
            company['feature_categories'].add(category_name)
        elif category_group == 'industry':
            company['industry_categories'].add(category_name)
    
    print(f"\nâœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ä¼æ¥­æ•°: {len(companies):,}ç¤¾")
    
    # ç›®æ¨™ã¨ã®æ¯”è¼ƒ
    target = 11341
    diff = len(companies) - target
    print(f"\nç›®æ¨™ä¼æ¥­æ•°: {target:,}ç¤¾")
    print(f"å·®åˆ†: {diff:+,}ç¤¾")
    if diff >= 0:
        print("ğŸ‰ ç›®æ¨™é”æˆï¼")
    
    # ã‚«ãƒ†ã‚´ãƒªå……å®Ÿåº¦ã®åˆ†æ
    print("\nã‚«ãƒ†ã‚´ãƒªå……å®Ÿåº¦åˆ†æ:")
    stats = {
        'area_only': 0,
        'price_only': 0,
        'feature_only': 0,
        'industry_only': 0,
        'multiple': 0,
        'all_categories': 0
    }
    
    for company in companies.values():
        has_area = len(company['area_categories']) > 0
        has_price = len(company['price_categories']) > 0
        has_feature = len(company['feature_categories']) > 0
        has_industry = len(company['industry_categories']) > 0
        
        category_count = sum([has_area, has_price, has_feature, has_industry])
        
        if category_count == 1:
            if has_area:
                stats['area_only'] += 1
            elif has_price:
                stats['price_only'] += 1
            elif has_feature:
                stats['feature_only'] += 1
            elif has_industry:
                stats['industry_only'] += 1
        elif category_count > 1:
            stats['multiple'] += 1
            if category_count == 4:
                stats['all_categories'] += 1
    
    print(f"  åœ°åŸŸã®ã¿: {stats['area_only']:,}ç¤¾")
    print(f"  ä¾¡æ ¼ã®ã¿: {stats['price_only']:,}ç¤¾")
    print(f"  ç‰¹å¾´ã®ã¿: {stats['feature_only']:,}ç¤¾")
    print(f"  æ¥­ç¨®ã®ã¿: {stats['industry_only']:,}ç¤¾")
    print(f"  è¤‡æ•°ã‚«ãƒ†ã‚´ãƒª: {stats['multiple']:,}ç¤¾")
    print(f"  å…¨ã‚«ãƒ†ã‚´ãƒªã‚ã‚Š: {stats['all_categories']:,}ç¤¾")
    
    # æœ€çµ‚CSVã‚’ä½œæˆ
    output_file = f"yuryoweb_final_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        
        writer.writerow([
            'company_name',
            'official_site_url',
            'yuryoweb_url',
            'address',
            'area_categories',
            'price_categories',
            'feature_categories',
            'industry_categories'
        ])
        
        for company in sorted(companies.values(), key=lambda x: x['company_name']):
            writer.writerow([
                company['company_name'],
                company['official_site_url'],
                company['yuryoweb_url'],
                'ï½œ'.join(sorted(company['addresses'])),
                'ï½œ'.join(sorted(company['area_categories'])),
                'ï½œ'.join(sorted(company['price_categories'])),
                'ï½œ'.join(sorted(company['feature_categories'])),
                'ï½œ'.join(sorted(company['industry_categories']))
            ])
    
    print(f"\nâœ… æœ€çµ‚CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«å: {output_file}")
    print(f"   ä¼æ¥­æ•°: {len(companies):,}ç¤¾")
    
    # ã‚µãƒãƒªãƒ¼CSVã‚‚ä½œæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
    summary_file = f"yuryoweb_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    
    with open(summary_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        
        writer.writerow([
            'company_name',
            'official_site_url',
            'address',
            'categories_count'
        ])
        
        for company in sorted(companies.values(), key=lambda x: x['company_name']):
            categories_count = (
                len(company['area_categories']) +
                len(company['price_categories']) +
                len(company['feature_categories']) +
                len(company['industry_categories'])
            )
            
            writer.writerow([
                company['company_name'],
                company['official_site_url'],
                list(company['addresses'])[0] if company['addresses'] else '',
                categories_count
            ])
    
    print(f"\nâœ… ã‚µãƒãƒªãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«å: {summary_file}")
    
    print(f"\nå‡¦ç†å®Œäº†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    return len(companies)

if __name__ == "__main__":
    count = merge_all_categories()
    print(f"\nğŸ æœ€çµ‚çµæœ: {count:,}ç¤¾")